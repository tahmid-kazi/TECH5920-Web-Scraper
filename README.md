# TECH5920-Web-Scraper
Web Scraper as the deliverable for BigCo Studio at Cornell Tech (Spring 2024)

# **Demo Project File structure**
We created a demoproject to demonstrate how the pipeline works. Here are some important demo files:
### TeamBidData_Test
`/TeamBidData_Test` is the directory that contains the team profile. Within it there is `teamprofile.txt`. Edit or replace this file to tune the pipeline's behavior to specific characteristics of the team.
### DemoProejct
The following shows a typical Project filestructue:
```
    /demoProject
    ├── databases                   # holds all results acquired from scraping modules, in csv format
    |   ├── nature_articles.csv             
    │   ├── pubmed_articles.csv           
    │   └── ... 
    ├── projectprofile           
    │   ├── projectContext.txt            # Any previously known knwoledge regaring the project
    │   ├── projectObjective.txt          # Contains the big objective of the project
    │   ├── queryPrompt.txt               # contains the "research question"
    │   └── uscraperDescription.txt       # Contains scraper module configurations
    ├── reports
    │   ├── index.html                  # A very barebone html page used display results
    │   ├── styles.css                  # associated styleing 
    │   ├── script.js                   # some nightmares from CS5356 Milestone 1 XD
    │   ├── Report_23_April_2024_20-01.json    # The actual reports generated by LLM Pipeline
    │   ├── Report_23_April_2024_20-01.json 
    │   ├── Report_23_April_2024_20-01.json 
    │   └── ... 
    └── scraping_pipeline              # Contains implementations of scarping modules
```

# **Scraping Pipeline Operation**

The scraping pipeline in this project is operated using the `parent_scraper.py` file located in `/demoProject/scraping_pipeline`. To run the scrapers, a scraper description file needs to be added and passed to the module as input (see example `scraperDescription.txt` in `/demoProject/projectprofile`). The format has to be maintained for it to work.
It is a bit *janky*, but we can change it later on, and we would only need to edit the `parent_scraper.py`.

## **Usage**

1. Navigate to the `scraping_pipeline` directory.
2. Add the scraper description file (e.g., `scraperDescription.txt`) to the `projectprofile` directory.
3. Run the scraping pipeline by executing the `parent_scraper.py` file while passing the scraping description file as an input. 

# **Insight Report Generation Pipeline**
`./insight_pipeline/insightGenerator.py` is the file that implements the report generaion pipeline. 

Associated Libraries needs to be installed:
```
$ python3 -m pip install langchain==0.0.351
$ python3 -m pip install -U openai 
```
In addition to langchain libraries, an API key needs to be requested from the OpenAI website (you need to create an account in order to do this) There are free credits available for new users. 

Once the API key is generated, save it to the local environment by executing the following command:
```
$ export OPENAI_API_KEY="YOUR_OPENAI_API_KEY_HERE"
```
## **Usage**
1. Open `./insight_pipeline/insightGenerator.py`
2. Edit Line 189 to set your project directory. The default project directory has been pointed to the `/demoProject` so you don't have to do anything if you want to run demoProject
3. If you wish to switch Team profile, you can do this either by editing the team profile text file. or by calling `insight.setTeamProfile("../TeamBigData_test")` in line 190 if you want to experiment with multiple teams
4. Finally, run insight generator to get the latest report:  (This might take up to 2 minutes to run depend on the database size and your query)
```
$ python3 insightGenerator.py
``` 

## **Visualize Reports in a browser**
Start the Server at your localhost port 8000 by running this command:
```
$ python3 -m http.server 8000
```
Once the server starts, you can open this url in your browser:
```
127.0.0.1:8000
```
Navigate to the `/demoProject/reports/index.html`, the page should automatically render and show you all reports being generated so far.


Team Members:
- Paul Andre Bisson
- Maanav Shah
- Tahmid Kazi
- Yifan Zhou
- Jace Hammer
